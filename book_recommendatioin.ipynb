{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0998409-f039-4a9e-8091-7f773adfd2e3",
   "metadata": {},
   "source": [
    "# Book Recommendation System using HF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeda06c-a778-4278-8f69-f985857fdd64",
   "metadata": {},
   "source": [
    "## 1) Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f391659-2481-4b94-a44b-cc830009ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ff35ffd-c369-408b-89bd-5efc9f540781",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data = load_dataset('vojtam/czech_books_descriptions', split=\"train+test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b246e4e0-bd3d-426b-ab10-f0eb4cf1e292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Volné pokračování historické detektivky Smrt nosí rudé škorně se opět odehrává ve středověké Praze, a to v prosinci roku 1399. Václav od Černého koně, podrychtář Starého Města pražského, řeší další případy. Nemá toho na svých bedrech málo: kromě zmizení biřice Vohnouta, požáru v radní síni, nepořádku v obecní pokladně a hledání viníků se musí potýkat s řadou dalších menších či větších problémů. Snaží se také odhalit identitu tajemných jurátů, kteří zřejmě stojí i za přepadením biskupova poselstva, a odkrýt podvody alchymisty s nekalou pověstí. A ke všemu občas na Václava svými tajnými ženskými zbraněmi skrytě zaútočí manželka Kateřina, toužící po nových šatech na očekávanou korunovaci...',\n",
       " 'Román vypráví o inteligentním robotu NDR-113, který v budoucím 21. stoletím slouží svému pánu tak dobře, že dostane i lidské jméno Andrew. Díky výrobní závadě totiž Andrew vykročil do života vybaven lidskou schopností milovat a touhou po sebezdokonalování. Neřešitelné problémy však nastanou, když Andrew zatouží stát se člověkem docela. Navzdory lidským předsudkům, zákonům robotiky a vlastním mechanickým omezením dokáže využít vědu i právní systém a na své pouti za nedosažitelným cílem se nakonec ocitá před děsivou volbou: aby uskutečnil svůj sen, musí zaplatit cenu nejvyšší.Překlad Jana Pavlíková.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data['text'][1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f2629-ae7a-483f-8d55-05d03fe9e311",
   "metadata": {},
   "source": [
    "## 2) Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c47c7e7-071b-4aff-98c6-0580b5fcc4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8c6711f-6ce4-44f1-a718-6b684eab2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "def create_embeddings(tokenizer, model, input_texts, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    \n",
    "    for i in range(0, len(input_texts), batch_size):\n",
    "        batch_texts = input_texts[i:i + batch_size]\n",
    "        \n",
    "        batch_dict = tokenizer(batch_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "        batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "        \n",
    "        # Get embeddings for batch\n",
    "        with torch.no_grad(): \n",
    "            outputs = model(**batch_dict)\n",
    "            batch_embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "            batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1)\n",
    "        \n",
    "        embeddings_list.append(batch_embeddings.cpu())\n",
    "\n",
    "        if (i + batch_size) % (batch_size * 10) == 0:\n",
    "            print(f\"Processed {i + batch_size}/{len(input_texts)} texts\")\n",
    "            \n",
    "    return torch.cat(embeddings_list, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b90ef0-69d1-49b8-966a-fbf89163387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 320/10091 texts\n",
      "Processed 640/10091 texts\n",
      "Processed 960/10091 texts\n",
      "Processed 1280/10091 texts\n",
      "Processed 1600/10091 texts\n",
      "Processed 1920/10091 texts\n",
      "Processed 2240/10091 texts\n",
      "Processed 2560/10091 texts\n",
      "Processed 2880/10091 texts\n",
      "Processed 3200/10091 texts\n",
      "Processed 3520/10091 texts\n",
      "Processed 3840/10091 texts\n",
      "Processed 4160/10091 texts\n",
      "Processed 4480/10091 texts\n",
      "Processed 4800/10091 texts\n",
      "Processed 5120/10091 texts\n",
      "Processed 5440/10091 texts\n",
      "Processed 5760/10091 texts\n",
      "Processed 6080/10091 texts\n",
      "Processed 6400/10091 texts\n",
      "Processed 6720/10091 texts\n",
      "Processed 7040/10091 texts\n",
      "Processed 7360/10091 texts\n",
      "Processed 7680/10091 texts\n",
      "Processed 8000/10091 texts\n",
      "Processed 8320/10091 texts\n",
      "Processed 8640/10091 texts\n",
      "Processed 8960/10091 texts\n",
      "Processed 9280/10091 texts\n",
      "Processed 9600/10091 texts\n",
      "Processed 9920/10091 texts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10091, 1024])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each input text should start with \"query: \" or \"passage: \", even for non-English texts.\n",
    "# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n",
    "input_texts = [\"passage: \" + text for text in books_data['text']]\n",
    "\n",
    "book_embeddings = create_embeddings(tokenizer, model, input_texts).cpu()\n",
    "#scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "#print(scores.tolist())\n",
    "book_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05ee5d23-1f7c-41a2-b629-c3556dab8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(query: str, n = 5):\n",
    "    input_query = \"query: \" + query\n",
    "    query_embedding = create_embeddings(tokenizer, model, input_query)\n",
    "    scores = ((query_embedding @ book_embeddings.T) * 100).detach().numpy()[0]\n",
    "    top_indices = np.argsort(scores)[-n:][::-1]\n",
    "\n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189e871a-1d82-4d28-97ef-42873596c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data.set_format('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3aa61939-5a6d-41ed-8dbf-c1334f5cd0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Úsměvy smutných mužů</td>\n",
       "      <td>Josef Formánek</td>\n",
       "      <td>Zápisky z léčebny.Když spadnete na dno, nezbýv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Připravte operační sál</td>\n",
       "      <td>Zdena Frýbová</td>\n",
       "      <td>Napínavý psychologický román s kriminální zápl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bude to bolet, doktore?</td>\n",
       "      <td>Adam Kay</td>\n",
       "      <td>Vítejte ve světě, kde je 97hodinový pracovní t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tribunál smrti</td>\n",
       "      <td>Noah Gordon</td>\n",
       "      <td>Není divu, že je lékařské prostředí čtenářsky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Občas lžu</td>\n",
       "      <td>Alice Feeney</td>\n",
       "      <td>Amber je upoutána na nemocniční lůžko. Nemůže ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blízký konec</td>\n",
       "      <td>Robin Cook</td>\n",
       "      <td>Napínavý román z prostředí onkologického centr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V bílém plášti</td>\n",
       "      <td>* antologie</td>\n",
       "      <td>Svorníkem povídkové sbírky jedněch z nejlepšíc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hlasy</td>\n",
       "      <td>Ursula Poznanski</td>\n",
       "      <td>Lidé, kteří si divoce mumlají sami pro sebe.Kt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Všichni jsme utkáni z hvězd</td>\n",
       "      <td>Rowan Coleman</td>\n",
       "      <td>Odejít z tohoto světa je snazší, když vás netr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Klíč</td>\n",
       "      <td>Kathryn Hughes</td>\n",
       "      <td>Zdravotní sestra Ellen Crosbyová nastoupí do n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title            author  \\\n",
       "0         Úsměvy smutných mužů    Josef Formánek   \n",
       "1       Připravte operační sál     Zdena Frýbová   \n",
       "2      Bude to bolet, doktore?          Adam Kay   \n",
       "3               Tribunál smrti       Noah Gordon   \n",
       "4                    Občas lžu      Alice Feeney   \n",
       "5                 Blízký konec        Robin Cook   \n",
       "6               V bílém plášti       * antologie   \n",
       "7                        Hlasy  Ursula Poznanski   \n",
       "8  Všichni jsme utkáni z hvězd     Rowan Coleman   \n",
       "9                         Klíč    Kathryn Hughes   \n",
       "\n",
       "                                                text  \n",
       "0  Zápisky z léčebny.Když spadnete na dno, nezbýv...  \n",
       "1  Napínavý psychologický román s kriminální zápl...  \n",
       "2  Vítejte ve světě, kde je 97hodinový pracovní t...  \n",
       "3  Není divu, že je lékařské prostředí čtenářsky ...  \n",
       "4  Amber je upoutána na nemocniční lůžko. Nemůže ...  \n",
       "5  Napínavý román z prostředí onkologického centr...  \n",
       "6  Svorníkem povídkové sbírky jedněch z nejlepšíc...  \n",
       "7  Lidé, kteří si divoce mumlají sami pro sebe.Kt...  \n",
       "8  Odejít z tohoto světa je snazší, když vás netr...  \n",
       "9  Zdravotní sestra Ellen Crosbyová nastoupí do n...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = find_similar(\"drama z prostředí nemocnice\", 10)\n",
    "books_data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "752c51df-b7d7-4796-bbf7-e850ed69f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('book_embeddings.pkl', 'wb') as file:\n",
    "    pickle.dump(book_embeddings, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087a1a9-d461-4c2c-a57c-39172aaf8a6c",
   "metadata": {},
   "source": [
    "> This cell should contain anything needed to run gradio app (without needing to run any of the cells above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1dfb3da-aade-4d85-a885-32295b9cdfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* Running on public URL: https://4c5199aafb9c84e08b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4c5199aafb9c84e08b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr \n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "\n",
    "with open('book_embeddings.pkl', 'rb') as file:\n",
    "    book_embeddings = pickle.load(file)\n",
    "\n",
    "model_checkpoint = 'intfloat/multilingual-e5-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModel.from_pretrained(model_checkpoint)\n",
    "\n",
    "books_data = load_dataset('vojtam/czech_books_descriptions', split=\"train+test\")\n",
    "books_data.set_format('pandas')\n",
    "\n",
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "def create_embeddings(tokenizer, model, input_texts, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    \n",
    "    for i in range(0, len(input_texts), batch_size):\n",
    "        batch_texts = input_texts[i:i + batch_size]\n",
    "        \n",
    "        batch_dict = tokenizer(batch_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # Get embeddings for batch\n",
    "        with torch.no_grad(): \n",
    "            outputs = model(**batch_dict)\n",
    "            batch_embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "            batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1)\n",
    "        \n",
    "        embeddings_list.append(batch_embeddings)\n",
    "\n",
    "        if (i + batch_size) % (batch_size * 10) == 0:\n",
    "            print(f\"Processed {i + batch_size}/{len(input_texts)} texts\")\n",
    "            \n",
    "    return torch.cat(embeddings_list, dim=0)\n",
    "\n",
    "def find_similar_books(query: str, n = 5):\n",
    "    input_query = \"query: \" + query\n",
    "    query_embedding = create_embeddings(tokenizer, model, input_query)\n",
    "    scores = ((query_embedding @ book_embeddings.T) * 100).detach().numpy()[0]\n",
    "    top_indices = np.argsort(scores)[-n:][::-1]\n",
    "\n",
    "    return  books_data[top_indices]\n",
    "\n",
    "\n",
    "\n",
    "css = \"\"\"\n",
    ".full-height-gallery {\n",
    "    height: calc(100vh - 250px);\n",
    "    overflow-y: auto;\n",
    "}\n",
    "#submit-btn {\n",
    "    background-color: #ff5b00;\n",
    "    color: #ffffff;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(css=css) as intf:\n",
    "    with gr.Row():\n",
    "        text_input = gr.Textbox(label=\"Popis knihy\", info = \"Zadejte popis knihy, kterou byste si chtěli přečíst a aplikace najde nejpodobněší knihy dle vašeho popisu\", placeholder='Zadejte popis, například \"drama z prostředí nemocnice\"')\n",
    "        n_books = gr.Number(value = 5, label = \"Počet knih\", info=\"Počet nejpodobnějších knih, které si přejete zobrazit\", minimum = 1, step = 1)\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Vyhledat knihy\", elem_id=\"submit-btn\")\n",
    "        clear_btn = gr.Button(\"Smazat\")\n",
    "    with gr.Row():\n",
    "        dataframe = gr.Dataframe(label=\"Podobné knihy\", show_label=False, elem_classes = [\"full-height-gallery\"])\n",
    "    \n",
    "    submit_btn.click(fn=find_similar_books, inputs=[text_input, n_books], outputs=dataframe)\n",
    "    clear_btn.click(fn=lambda: [None, []], inputs=None, outputs=[text_input, dataframe])\n",
    "\n",
    "intf.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac2822-227d-4e95-9327-fa0d058411bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
